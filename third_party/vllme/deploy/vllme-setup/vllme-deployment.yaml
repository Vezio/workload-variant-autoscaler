apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllme-deployment
  labels:
    inferno.server.managed: "true"
    inferno.server.name: vllm-001
    inferno.server.model: llama_13b
    inferno.server.class: Premium
    inferno.server.allocation.accelerator: MI250
    inferno.server.allocation.maxbatchsize: "8"
    inferno.server.load.rpm: "30"
    inferno.server.load.numtokens: "1560"
spec:
  replicas: 2
  selector:
    matchLabels:
      app: vllme
  template:
    metadata:
      labels:
        app: vllme
    spec:
      containers:
      - name: vllme
        # image: vllme:latest
        image: quay.io/vishakharamani/vllme:latest
        # imagePullPolicy: Never
        imagePullPolicy: Always
        ports:
        - containerPort: 80
